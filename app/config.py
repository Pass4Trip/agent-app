# voice_assistant/config.py

import os
from dotenv import load_dotenv

# Load environment variables from the .env file
load_dotenv()

class Config:
    """
    Configuration class to hold the model selection and API keys.
    
    Attributes:
        TRANSCRIPTION_MODEL (str): The model to use for transcription ('openai', 'groq', 'deepgram', 'fastwhisperapi', 'local').
        RESPONSE_MODEL (str): The model to use for response generation ('openai', 'groq', 'local').
        TTS_MODEL (str): The model to use for text-to-speech ('openai', 'deepgram', 'elevenlabs', 'local').
        OPENAI_API_KEY (str): API key for OpenAI services.
        GROQ_API_KEY (str): API key for Groq services.
        DEEPGRAM_API_KEY (str): API key for Deepgram services.
        ELEVENLABS_API_KEY (str): API key for ElevenLabs services.
        LOCAL_MODEL_PATH (str): Path to the local model.
    """
    # Model selection
    TRANSCRIPTION_MODEL = 'fastwhisperapi'  # possible values: openai, groq, deepgram, fastwhisperapi

    # temp file generated by the initial STT model
    INPUT_AUDIO = "test.mp3"
